{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "This notebook will contain projects and scripts related to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning\n",
    "Machine learning is a field of artificial intelligence that uses statistical techniques to give computer systems the ability to learn from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Data preprocessing involves transforming raw data into an understandable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of data preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = {'A': [1, 2, 3, 4, 5], 'B': [5, 4, 3, 2, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "Regression models are used to predict a continuous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "Classification models are used to predict a categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a classification model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = DecisionTreeClassifier().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a support vector machine\n",
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = RandomForestClassifier().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = GradientBoostingClassifier().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a k-nearest neighbors classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = KNeighborsClassifier().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a naive bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = GaussianNB().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a neural network classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = MLPClassifier().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a linear discriminant analysis classifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = LinearDiscriminantAnalysis().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a quadratic discriminant analysis classifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = QuadraticDiscriminantAnalysis().fit(X, y)\n",
    "print(clf.predict([[2, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Techniques\n",
    "Clustering techniques are used to group similar data points together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a clustering technique\n",
    "from sklearn.cluster import KMeans\n",
    "X = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]]\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a DBSCAN clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "dbscan = DBSCAN()\n",
    "print(dbscan.fit_predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a hierarchical clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "clustering = AgglomerativeClustering()\n",
    "print(clustering.fit_predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a Gaussian mixture model\n",
    "from sklearn.mixture import GaussianMixture\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "print(gmm.fit_predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Dimensionality reduction techniques are used to reduce the number of features in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print(pca.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a singular value decomposition\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit(X)\n",
    "print(svd.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "tsne = TSNE(n_components=2)\n",
    "print(tsne.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Basics\n",
    "Deep learning is a subset of machine learning that uses neural networks with many layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a hidden Markov model\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "X = np.array([[0.0, 0.0], [0.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\n",
    "model = hmm.GaussianHMM(n_components=2)\n",
    "model.fit(X)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a reinforcement learning model\n",
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "observation = env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        observation = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a natural language processing model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['This is the first document.', 'This is the second document.']\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis\n",
    "Time series analysis involves analyzing time-ordered data points to extract meaningful statistics and identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a time series analysis model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dates = pd.date_range('20230101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "Anomaly detection involves identifying rare items, events, or observations that raise suspicions by differing significantly from the majority of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an anomaly detection model\n",
    "from sklearn.ensemble import IsolationForest\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8], [100, 200]]\n",
    "clf = IsolationForest().fit(X)\n",
    "print(clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems\n",
    "Recommender systems are used to predict the preference or rating that a user would give to an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a recommender system\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "neigh.fit(X)\n",
    "print(neigh.kneighbors([[1, 2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
